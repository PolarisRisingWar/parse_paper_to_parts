{
    "图 1-1": "图1-1 CBOW 利用上下文预测中心词“吃”及Skip-gram 利用中心词“吃”来预测词上下文",
    "图 1-2": "图 1-2 Doc2vec 添加段落特征预测下一个词",
    "图2-1": "图2-1 Quick-thoughts 模型结构图",
    "图2-2": "图2-2 传统Transformer 模型各阶段流程图",
    "图2-3": "图2-3 Transformer-XL 模型各阶段流程图",
    "图2-4": "图2-4 双向长短期记忆网络结构图",
    "图2-5": "图2-5 注意力机制工作流程图",
    "图3-1": "图3-1 基于海关虚假贸易案件的罚款金额预测模型框架图",
    "图3-2": "图3-2 案件文本句向量编码模块示意图",
    "图3-3": "图3-3 文本预处理操作示例图",
    "图3-4": "图3-4 基于Transformer-XL 改进的Quick-thoughts 模型编码流程图",
    "图3-5": "图3-5 多头注意力层流程图",
    "图3-6": "图3-6 循环机制示例图",
    "图3-7": "图3-7 基于Encoder-Decoder 的罚款金额预测模块结构图",
    "图3-8": "图3-8 Bi-LSTM Encoder 结构示意图",
    "图3-9": "图3-9 注意力机制结构",
    "图3-10": "图3-10 Decoder 模块结构示意图",
    "图3-11": "图3-11 案件描述文本矩阵图",
    "图4-1": "图4-1罚款金额数据分布直方图",
    "图4-2": "图4-2 案情离散化示例",
    "图4-3": "图4-3 对于罚款金额预测注意力分布可视化",
    "图4-4": "图4-4 不同词向量维度在两种评估指标上的表现",
    "图4-5": "图4-5 不同神经元个数与隐含层层数在两种评估指标上的表现",
    "图4-6": "图4-6 Dropout 的敏感实验结果"
}